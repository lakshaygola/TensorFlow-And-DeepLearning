{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "TransferLearning-Word Embedding.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lakshaygola/TensorFlow-And-DeepLearning/blob/main/TransferLearning_Word_Embedding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRgMkiuqgWiK",
        "outputId": "e62c3527-7e3b-42c0-ef4e-5093236bf513"
      },
      "source": [
        "# Jovian Commit Essentials\n",
        "# Please retain and execute this cell without modifying the contents for `jovian.commit` to work\n",
        "!pip install jovian --upgrade -q\n",
        "import jovian\n",
        "jovian.set_project('transferlearning-word-embedding')\n",
        "jovian.set_colab_id('1C2XHCbVR8oEnNkQ1DK3gGpLb_0DgnBD9')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |████▊                           | 10kB 19.1MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 20kB 22.3MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 30kB 25.6MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 40kB 26.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 51kB 27.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 61kB 20.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 4.9MB/s \n",
            "\u001b[?25h  Building wheel for uuid (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "055WGallpUoc",
        "outputId": "6063607c-4857-4353-9417-5711e14e6a58"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGM9WKZtkIzX"
      },
      "source": [
        "project_name = 'transferlearning-word-embedding'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUjmQ60ygWia"
      },
      "source": [
        "# TransferLearning With Word Embedding\n",
        "\n",
        "We will be using pretrained model for this project of word embedding.\n",
        "\n",
        "Pretraind Model which we are using in the notebook is GloVe\n",
        "\n",
        "We will create the small dataset and try to apply transfer learning on that and calculate the accuracy of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHTRVndCgWic",
        "outputId": "6743fb66-2645-4faa-9ecb-5d84a354c29c"
      },
      "source": [
        "!pip install jovian --upgrade --quiet\n",
        "!pip install opendatasets"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting opendatasets\n",
            "  Downloading https://files.pythonhosted.org/packages/18/99/aaa3ebec81dc347302e730e0daff61735ed2f3e736129553fb3f9bf67ed3/opendatasets-0.1.10-py3-none-any.whl\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from opendatasets) (7.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from opendatasets) (4.41.1)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (from opendatasets) (1.5.12)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (2.8.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (2.23.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (4.0.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (2020.12.5)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle->opendatasets) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle->opendatasets) (3.0.4)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
            "Installing collected packages: opendatasets\n",
            "Successfully installed opendatasets-0.1.10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WLUdlrwgWic"
      },
      "source": [
        "# Importing some necessary libraries\n",
        "import jovian\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import one_hot, Tokenizer\n",
        "from tensorflow.keras.layers import Dense, Flatten, Embedding\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbMhcbHWgWid",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfa0b0dc-8160-48d7-e4c8-ee67dac0855d"
      },
      "source": [
        "# Creating the sample dataset\n",
        "doc = ['Well done', \n",
        "       'Great Effort', \n",
        "       'Good Work', \n",
        "       'Nice',\n",
        "       'Excellent',\n",
        "       'you can do better', \n",
        "       'have to submit before deadline', \n",
        "       'This can be done better',\n",
        "       'Poor', \n",
        "       'Not good',\n",
        "       'Poor effort', \n",
        "       'Its ok this time but improve',\n",
        "       'ok ok']\n",
        "\n",
        "# Creating the label for the data\n",
        "label = [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1]\n",
        "\n",
        "# 1 - Good remark\n",
        "# 0 - Bad remark\n",
        "doc"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Well done',\n",
              " 'Great Effort',\n",
              " 'Good Work',\n",
              " 'Nice',\n",
              " 'Excellent',\n",
              " 'you can do better',\n",
              " 'have to submit before deadline',\n",
              " 'This can be done better',\n",
              " 'Poor',\n",
              " 'Not good',\n",
              " 'Poor effort',\n",
              " 'Its ok this time but improve',\n",
              " 'ok ok']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHtBOR6Undan",
        "outputId": "17d67500-7a51-4b3e-cb91-f600594f23cc"
      },
      "source": [
        "# Converting the label into array\n",
        "label  = np.array(label)\n",
        "label"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-AEC25DoRlW",
        "outputId": "195b9c96-1fae-4cc0-b1a6-053a24eb9510"
      },
      "source": [
        "# Creating the tokenizer (help us to determin the vocal size)\n",
        "token = Tokenizer()\n",
        "token.fit_on_texts(doc)\n",
        "vocal_size = len(token.word_index) + 1\n",
        "print(vocal_size)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "27\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4gd_ZXh23at",
        "outputId": "7d21d8cc-fcc9-4128-8dd4-e43d33806d58"
      },
      "source": [
        "# Converting the text into integer values\n",
        "encoded_doc = token.texts_to_sequences(doc)\n",
        "print(encoded_doc)\n",
        "print(token.word_index)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[9, 2], [10, 3], [4, 11], [12], [13], [14, 5, 15, 6], [16, 17, 18, 19, 20], [7, 5, 21, 2, 6], [8], [22, 4], [8, 3], [23, 1, 7, 24, 25, 26], [1, 1]]\n",
            "{'ok': 1, 'done': 2, 'effort': 3, 'good': 4, 'can': 5, 'better': 6, 'this': 7, 'poor': 8, 'well': 9, 'great': 10, 'work': 11, 'nice': 12, 'excellent': 13, 'you': 14, 'do': 15, 'have': 16, 'to': 17, 'submit': 18, 'before': 19, 'deadline': 20, 'be': 21, 'not': 22, 'its': 23, 'time': 24, 'but': 25, 'improve': 26}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vSlNaJf57SN",
        "outputId": "d2427045-956c-47f6-d9bf-1f9c1465ea15"
      },
      "source": [
        "# Finding the maximum length of the sentence in the list of text\n",
        "length = max([len(sens.split()) for sens in doc])\n",
        "print(length)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdWq4oki5Tte",
        "outputId": "a0f876e2-b107-4842-d45c-491f9cb67c84"
      },
      "source": [
        "# Making the length of each sentence equal\n",
        "padding_doc = pad_sequences(encoded_doc, maxlen = length, padding = 'post')\n",
        "print(padding_doc)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 9  2  0  0  0  0]\n",
            " [10  3  0  0  0  0]\n",
            " [ 4 11  0  0  0  0]\n",
            " [12  0  0  0  0  0]\n",
            " [13  0  0  0  0  0]\n",
            " [14  5 15  6  0  0]\n",
            " [16 17 18 19 20  0]\n",
            " [ 7  5 21  2  6  0]\n",
            " [ 8  0  0  0  0  0]\n",
            " [22  4  0  0  0  0]\n",
            " [ 8  3  0  0  0  0]\n",
            " [23  1  7 24 25 26]\n",
            " [ 1  1  0  0  0  0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8850GEH6h3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fb96873-5275-485c-a3de-eeecd76756d3"
      },
      "source": [
        "# Open the file of the model\n",
        "embedded_weights = dict()\n",
        "f = open('/content/drive/MyDrive/Models/glove.6B.zip (Unzipped Files)/glove.6B.100d.txt')\n",
        "\n",
        "for line in f:\n",
        "  values = line.split()\n",
        "  word = values[0]\n",
        "  coeff = np.asarray(values[1:], dtype = 'float32')\n",
        "  embedded_weights[word] = coeff\n",
        "f.close()\n",
        "print(len(embedded_weights))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "400000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wn-ZKAYkn70T",
        "outputId": "a43678cc-2790-4e61-aa87-4cf257c38e5f"
      },
      "source": [
        "# Creating the matrix with the weights of the GloVe\n",
        "embedded_matrix = np.zeros((vocal_size, 100))\n",
        "for word, value in token.word_index.items():\n",
        "  embedded_vector = embedded_weights.get(word)\n",
        "  if embedded_vector is not None:\n",
        "    embedded_matrix[value] = embedded_vector\n",
        "print(embedded_matrix)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.21295001  0.03707     1.01240003 ... -0.26216    -0.069477\n",
            "  -0.070536  ]\n",
            " [-0.2978      0.31147    -0.14937    ... -0.22709    -0.029261\n",
            "   0.4585    ]\n",
            " ...\n",
            " [-0.024221   -0.034855    0.35710001 ... -0.087568    0.25961\n",
            "   0.050783  ]\n",
            " [-0.057078    0.39873999  0.68861002 ... -0.19357    -0.030606\n",
            "   0.2397    ]\n",
            " [ 0.017839   -0.010497    0.022748   ... -0.50676     0.70486999\n",
            "   0.27588001]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80Uit7vKDJEH",
        "outputId": "a83010e5-16ed-486d-8aff-23dbb875868b"
      },
      "source": [
        "# Now Creating the model\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocal_size, 100, input_length= length, weights = [embedded_matrix], trainable = False))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1, 'sigmoid'))\n",
        "\n",
        "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, 6, 100)            2700      \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 600)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 601       \n",
            "=================================================================\n",
            "Total params: 3,301\n",
            "Trainable params: 601\n",
            "Non-trainable params: 2,700\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4lXXT6NFMDw"
      },
      "source": [
        "# Now lets make the prediction and see the accuracy of the model\n",
        "model.fit(padding_doc, label, epochs = 45, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCwCooKwGCme",
        "outputId": "f507d741-48ef-4ea4-9762-5434ac79c193"
      },
      "source": [
        "# Evaluating the model\n",
        "loss, accuracy = model.evaluate(padding_doc, label)\n",
        "print('\\nLoss of the model: ', loss)\n",
        "print('Accuracy of the model: ', accuracy*100)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 18ms/step - loss: 0.3179 - accuracy: 1.0000\n",
            "\n",
            "Loss of the model:  0.3178699314594269\n",
            "Accuracy of the model:  100.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "quSMm9BNGijq",
        "outputId": "e06ac676-d993-47a4-b303-691a87573a99"
      },
      "source": [
        "jovian.commit(project = project_name)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[jovian] Detected Colab notebook...\u001b[0m\n",
            "[jovian] Please enter your API key ( from https://jovian.ai/ ):\u001b[0m\n",
            "API KEY: ··········\n",
            "[jovian] Uploading colab notebook to Jovian...\u001b[0m\n",
            "[jovian] Capturing environment..\u001b[0m\n",
            "[jovian] Committed successfully! https://jovian.ai/lakshaygola/transferlearning-word-embedding\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'https://jovian.ai/lakshaygola/transferlearning-word-embedding'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2pXnpnxGrvb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}