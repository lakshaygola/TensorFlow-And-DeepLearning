{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Word-Embedding-Using-Tensorflow.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lakshaygola/TensorFlow-And-DeepLearning/blob/main/Word_Embedding_Using_Tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FN3Pvdl4pHCD",
        "outputId": "4110d669-3d77-4bb0-e57f-6fb800044fa8"
      },
      "source": [
        "# Jovian Commit Essentials\n",
        "# Please retain and execute this cell without modifying the contents for `jovian.commit` to work\n",
        "!pip install jovian --upgrade -q\n",
        "import jovian\n",
        "jovian.set_project('word-embedding-using-tensorflow')\n",
        "jovian.set_colab_id('1fWnUjP93qRf6CP3x7BJfpHyVxYr099y8')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |████▊                           | 10kB 17.9MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 20kB 20.4MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 30kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 40kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 51kB 5.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 61kB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 2.8MB/s \n",
            "\u001b[?25h  Building wheel for uuid (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dauGvDwlpHCK"
      },
      "source": [
        "# word-embedding-using-tensorflow\n",
        "\n",
        "Use the \"Run\" button to execute the code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W74TwiMppHCL",
        "outputId": "0bf3381d-13e7-4755-d1ad-e97d4004b59f"
      },
      "source": [
        "!pip install jovian --upgrade --quiet\n",
        "!pip install opendatasets"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting opendatasets\n",
            "  Downloading https://files.pythonhosted.org/packages/18/99/aaa3ebec81dc347302e730e0daff61735ed2f3e736129553fb3f9bf67ed3/opendatasets-0.1.10-py3-none-any.whl\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (from opendatasets) (1.5.12)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from opendatasets) (4.41.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from opendatasets) (7.1.2)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (1.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (2.23.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (2020.12.5)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (1.24.3)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (4.0.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (2.8.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle->opendatasets) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle->opendatasets) (3.0.4)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
            "Installing collected packages: opendatasets\n",
            "Successfully installed opendatasets-0.1.10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwNed2w8pHCM"
      },
      "source": [
        "project_name = 'word-embedding-using-tensorflow'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRBEP4D6pdOq"
      },
      "source": [
        "# Importing some necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import one_hot\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9A2Vq7E__5yl"
      },
      "source": [
        "# Creating the text data\n",
        "\n",
        "Now creating the text data so we can perform word embedding on it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QM40kXvCqtLm",
        "outputId": "d6cf57bb-5c28-4292-9161-b03ac9276515"
      },
      "source": [
        "sentences = ['This is good coding platform', \n",
        "             'Valorant is good game', \n",
        "             'I have to control my instance of playing game', \n",
        "             'There is a glass of water',\n",
        "             'there is a glass of beer', \n",
        "             'He has some good programming skills']\n",
        "sentences"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['This is good coding platform',\n",
              " 'Valorant is good game',\n",
              " 'I have to control my instance of playing game',\n",
              " 'There is a glass of water',\n",
              " 'there is a glass of beer',\n",
              " 'He has some good programming skills']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3TSdp14qvZp"
      },
      "source": [
        "# Noe defining the vocabulary size (hyperparameter you can change the values)\n",
        "vocal_size= 10000"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6h9OOgtA5b4",
        "outputId": "0becdae3-5a8e-4c12-def3-82813ad58b85"
      },
      "source": [
        "# Now perfoming one hot encoding on the text data\n",
        "# Convert the word into number which represent the index of the word in vocal\n",
        "Onehot_repr = [one_hot(input_text = word, n = vocal_size) for word in sentences]\n",
        "Onehot_repr"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[9361, 2231, 918, 3564, 9433],\n",
              " [2051, 2231, 918, 6568],\n",
              " [8865, 4300, 6762, 3684, 5915, 329, 2150, 3904, 6568],\n",
              " [5981, 2231, 6482, 7939, 2150, 9840],\n",
              " [5981, 2231, 6482, 7939, 2150, 6358],\n",
              " [6805, 7167, 8500, 918, 8025, 4174]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5spT0gn2EMpw",
        "outputId": "da79765c-30d2-4fe1-bbef-3fc99c06e451"
      },
      "source": [
        "# Finding the maximum length of the sentence in the text data\n",
        "lengths = [len(sen.split()) for sen in sentences]\n",
        "print('Maximum length of the sentence in the text data: ', max(lengths))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Maximum length of the sentence in the text data:  9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwSVaYzcBNdD",
        "outputId": "2fcb2b96-7a1f-452a-f6cb-8ed4efe50e55"
      },
      "source": [
        "# So before passing the vector of sentence in the word embedding layer \n",
        "# the length of the sentence should be same\n",
        "text_data = pad_sequences(Onehot_repr, maxlen= 10)\n",
        "text_data"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0,    0,    0,    0,    0, 9361, 2231,  918, 3564, 9433],\n",
              "       [   0,    0,    0,    0,    0,    0, 2051, 2231,  918, 6568],\n",
              "       [   0, 8865, 4300, 6762, 3684, 5915,  329, 2150, 3904, 6568],\n",
              "       [   0,    0,    0,    0, 5981, 2231, 6482, 7939, 2150, 9840],\n",
              "       [   0,    0,    0,    0, 5981, 2231, 6482, 7939, 2150, 6358],\n",
              "       [   0,    0,    0,    0, 6805, 7167, 8500,  918, 8025, 4174]],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HsDazMnGUU1"
      },
      "source": [
        "# Performing word embedding\n",
        "\n",
        "Now as we create the vector of same dimension for all the sentence. Now making the word embedding layer to create more meaning full vector representation of the word."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pb78qOatGTRr"
      },
      "source": [
        "# Feature dimension (Hyperparameter)\n",
        "featDim = 10"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ONd9Te3Fx02",
        "outputId": "960e5325-e8b5-4946-8ab6-31ee4ea3ad53"
      },
      "source": [
        "# Word Embedding\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocal_size, featDim, input_length= 10))\n",
        "model.compile('adam', 'mse')\n",
        "model.summary()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, 10, 10)            100000    \n",
            "=================================================================\n",
            "Total params: 100,000\n",
            "Trainable params: 100,000\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "veCSd7BpLD7Y",
        "outputId": "6a599959-c498-4755-f97a-6ea3946a70e9"
      },
      "source": [
        "# Now lets take the prediction on the word vector\n",
        "model.predict(text_data[0])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 10) for input KerasTensor(type_spec=TensorSpec(shape=(None, 10), dtype=tf.float32, name='embedding_4_input'), name='embedding_4_input', description=\"created by layer 'embedding_4_input'\"), but it was called on an input with incompatible shape (None, 1).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[-0.03812175,  0.02274359, -0.03946485, -0.04256481,\n",
              "          0.00746156, -0.01723599,  0.03743974, -0.0070058 ,\n",
              "          0.0425102 ,  0.0290316 ]],\n",
              "\n",
              "       [[-0.03812175,  0.02274359, -0.03946485, -0.04256481,\n",
              "          0.00746156, -0.01723599,  0.03743974, -0.0070058 ,\n",
              "          0.0425102 ,  0.0290316 ]],\n",
              "\n",
              "       [[-0.03812175,  0.02274359, -0.03946485, -0.04256481,\n",
              "          0.00746156, -0.01723599,  0.03743974, -0.0070058 ,\n",
              "          0.0425102 ,  0.0290316 ]],\n",
              "\n",
              "       [[-0.03812175,  0.02274359, -0.03946485, -0.04256481,\n",
              "          0.00746156, -0.01723599,  0.03743974, -0.0070058 ,\n",
              "          0.0425102 ,  0.0290316 ]],\n",
              "\n",
              "       [[-0.03812175,  0.02274359, -0.03946485, -0.04256481,\n",
              "          0.00746156, -0.01723599,  0.03743974, -0.0070058 ,\n",
              "          0.0425102 ,  0.0290316 ]],\n",
              "\n",
              "       [[-0.00547989, -0.03432592,  0.01736701, -0.04504509,\n",
              "          0.00277674, -0.03092035, -0.03712449, -0.0430085 ,\n",
              "          0.02280975, -0.01361096]],\n",
              "\n",
              "       [[-0.04147841,  0.00332307,  0.0142383 , -0.04255829,\n",
              "          0.04181978, -0.00619568,  0.00847125, -0.01701393,\n",
              "          0.02084556,  0.00975056]],\n",
              "\n",
              "       [[-0.01691692,  0.03123771,  0.0272874 , -0.00775504,\n",
              "          0.04273316, -0.00969893, -0.0445598 ,  0.01245738,\n",
              "         -0.01650276,  0.03160472]],\n",
              "\n",
              "       [[-0.02966801, -0.01928822, -0.02271843,  0.04662205,\n",
              "         -0.03890594,  0.04282865, -0.02247697,  0.04640598,\n",
              "         -0.02519476,  0.01684178]],\n",
              "\n",
              "       [[-0.0142671 ,  0.00949126,  0.00077293,  0.04055332,\n",
              "         -0.04041111,  0.00401744, -0.02820655, -0.03235777,\n",
              "          0.00060349, -0.01673291]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZ3tJdlfL89n"
      },
      "source": [
        "EmbeddedVector = model.predict(text_data)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQPl8TQBMKBt",
        "outputId": "0c1c7a9f-ef99-4a95-d3cc-e75b79e0cac1"
      },
      "source": [
        "# Comparing the One hot encoding and the word embedding \n",
        "print(text_data[5], '\\n')\n",
        "print(\"After perfoming the word embedding: \\n\")\n",
        "print(EmbeddedVector[5])"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[   0    0    0    0 6805 7167 8500  918 8025 4174] \n",
            "\n",
            "After perfoming the word embedding: \n",
            "\n",
            "[[-0.03812175  0.02274359 -0.03946485 -0.04256481  0.00746156 -0.01723599\n",
            "   0.03743974 -0.0070058   0.0425102   0.0290316 ]\n",
            " [-0.03812175  0.02274359 -0.03946485 -0.04256481  0.00746156 -0.01723599\n",
            "   0.03743974 -0.0070058   0.0425102   0.0290316 ]\n",
            " [-0.03812175  0.02274359 -0.03946485 -0.04256481  0.00746156 -0.01723599\n",
            "   0.03743974 -0.0070058   0.0425102   0.0290316 ]\n",
            " [-0.03812175  0.02274359 -0.03946485 -0.04256481  0.00746156 -0.01723599\n",
            "   0.03743974 -0.0070058   0.0425102   0.0290316 ]\n",
            " [ 0.0085168   0.00405276 -0.0012936   0.00103389  0.00891359 -0.03169588\n",
            "  -0.03667386 -0.032701    0.01790031  0.03706059]\n",
            " [-0.02320543  0.03061137 -0.03680325 -0.03107295 -0.00966263  0.0356813\n",
            "  -0.04714104 -0.00927428  0.00927382 -0.01940612]\n",
            " [ 0.03176281 -0.03204861  0.00565214 -0.0315025   0.03464626  0.02137531\n",
            "  -0.03935847 -0.01330533  0.01919064  0.00700337]\n",
            " [-0.01691692  0.03123771  0.0272874  -0.00775504  0.04273316 -0.00969893\n",
            "  -0.0445598   0.01245738 -0.01650276  0.03160472]\n",
            " [-0.00728948  0.02252549 -0.00356261 -0.04810483 -0.02679638 -0.03345869\n",
            "   0.04654272 -0.04898623  0.00276345  0.04271648]\n",
            " [ 0.02824955  0.0022952  -0.04920957  0.02152183 -0.02173229  0.03492179\n",
            "  -0.01166404 -0.01646768 -0.02412811  0.01004054]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "NFWf8vn5MXSW",
        "outputId": "284b23e9-5db1-4639-f1bb-8b05200012bd"
      },
      "source": [
        "import jovian\n",
        "jovian.commit(project = project_name)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[jovian] Detected Colab notebook...\u001b[0m\n",
            "[jovian] Please enter your API key ( from https://jovian.ai/ ):\u001b[0m\n",
            "API KEY: ··········\n",
            "[jovian] Uploading colab notebook to Jovian...\u001b[0m\n",
            "[jovian] Capturing environment..\u001b[0m\n",
            "[jovian] Committed successfully! https://jovian.ai/lakshaygola/word-embedding-using-tensorflow\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'https://jovian.ai/lakshaygola/word-embedding-using-tensorflow'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFcalMVxM4aq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}