{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN Fashion MNIST.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNGsXzYGLGa4t1QujyZ7Wpm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lakshaygola/TensorFlow-And-DeepLearning/blob/main/CNN_Fashion_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDEt87Tc2Yh9"
      },
      "source": [
        "# Convolutional Neural Network (CNN)\n",
        "\n",
        "This architecture of neural network used for image classification or to analyze visual imagery. In this we  have a different kernel which help us to achive different outcome from the image and when we train the CNN we usually changing the values of the kernel so that we get the better outcome from the model\n",
        "\n",
        "In this particular example we are using Fashion MNIST dataset which was easily available on kaggle but we are using built in dataset in keras.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxU5bVos5dYG",
        "outputId": "a00d52b0-ff83-4b98-d060-c9576f0c11a1"
      },
      "source": [
        "pip install -q -U keras-tuner"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |█████▏                          | 10kB 16.5MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 20kB 21.1MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 30kB 18.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 40kB 15.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 51kB 12.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 61kB 10.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 4.9MB/s \n",
            "\u001b[?25h  Building wheel for keras-tuner (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for terminaltables (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tnDuPx32Qjd"
      },
      "source": [
        "# Importing the necessary libraries \n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import kerastuner as kt\n",
        "from tensorflow.keras.models import Model\n",
        "import keras.layers as layer\n",
        "from kerastuner import RandomSearch\n",
        "from kerastuner.engine.hyperparameters import HyperParameters\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwL0h_CV6R_s"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "In this dataset we have different images of the clothes and they all classified in some different classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAMORrk95FE1"
      },
      "source": [
        "# Loading the dataset\n",
        "image_data = keras.datasets.fashion_mnist"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsUWkFlW5rpR",
        "outputId": "19db34a6-b73e-48fa-ba1e-75cde1987e93"
      },
      "source": [
        "# Making training and test data split\n",
        "(train_image, train_label),  (test_image, test_label) = image_data.load_data() "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzVRwVfn9IEY"
      },
      "source": [
        "# Preprocessing of the images\n",
        "\n",
        "1. Normalizing the image of the dataset\n",
        "\n",
        "2. Adding color channel in the shape of the image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlvoOjWs6OOt"
      },
      "source": [
        "# Normalizing the values present (ranging the values between 0 and 1)\n",
        "train_image = train_image / 255.0\n",
        "test_image = test_image / 255.0"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqNFapwj73XW",
        "outputId": "a1970a0f-cd42-4935-ae3c-c65f9602af22"
      },
      "source": [
        "# Cheaking the shape of the image \n",
        "print(train_image[0].shape)\n",
        "\n",
        "# Reshaping the images of train set and test set\n",
        "train_image = train_image.reshape(len(train_image), 28, 28, 1)\n",
        "test_image = test_image.reshape(len(test_image), 28, 28, 1)       # Adding one color channel because dataset contain gray scale image\n",
        "print(train_image[0].shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(28, 28)\n",
            "(28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqN9HX5d__pF"
      },
      "source": [
        "# Making the model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrnktIFZAEiE"
      },
      "source": [
        "# Model building function and using keras tuner\n",
        "def build_model(hp):\n",
        "  model= keras.Sequential([\n",
        "          # 1st layer\n",
        "          layer.Conv2D(\n",
        "              filters= hp.Int('conv2d_filter', min_value = 32, max_value = 512, step = 16),\n",
        "              kernel_size = hp.Choice('kernel_size', values = [3, 5]),\n",
        "              activation= 'relu',\n",
        "              input_shape= (28,28,1)\n",
        "          ),\n",
        "\n",
        "          # 2nd layer\n",
        "          layer.Conv2D(\n",
        "              filters= hp.Int('conv2d_filter', min_value = 32, max_value = 128, step = 16),\n",
        "              kernel_size = hp.Choice('kernel_size', values = [3, 5]),\n",
        "              activation = 'relu'\n",
        "          ),\n",
        "\n",
        "          # 3rd layer\n",
        "          layer.Conv2D(\n",
        "              filters= hp.Int('conv2d_filter', min_value = 32, max_value = 64, step = 16),\n",
        "              kernel_size = hp.Choice('kernel_size', values = [3, 5]),\n",
        "              activation = 'relu'\n",
        "          ), \n",
        "          # Flattern layer\n",
        "          layer.Flatten(), \n",
        "          # 1st Dense layer\n",
        "          layer.Dense(units = hp.Int('unit_num', min_value = 32, max_value = 64, step = 16), \n",
        "                      activation = 'relu'),\n",
        "          # 2nd Dense layer\n",
        "          layer.Dense(10, activation= 'sigmoid')\n",
        "  ])\n",
        "\n",
        "  model.compile(optimizer= keras.optimizers.Adam(hp.Choice('learning_rate', values = [0.001, 0.0001])),\n",
        "                loss = 'sparse_categorical_crossentropy',\n",
        "                metrics = ['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqBYoVKwJ-Ea"
      },
      "source": [
        "# Searching best pair of hyperparameter for the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hj6Cr1xSF22f"
      },
      "source": [
        "# Searching for the best values of hyperparameter for our model\n",
        "tuner = RandomSearch(build_model, \n",
        "                     objective = 'val_accuracy', \n",
        "                     max_trials = 2, \n",
        "                     directory= 'model_output', \n",
        "                     project_name = 'fashion_model')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkPP3C6WG_xf",
        "outputId": "b4995055-00d4-401b-f268-0d4f9c114aba"
      },
      "source": [
        "# Perform searching for the different set to hyperparameters\n",
        "tuner.search(train_image, train_label, validation_split = 0.3, epochs = 3)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trial 2 Complete [00h 01m 57s]\n",
            "val_accuracy: 0.9021111130714417\n",
            "\n",
            "Best val_accuracy So Far: 0.9042222499847412\n",
            "Total elapsed time: 00h 09m 00s\n",
            "INFO:tensorflow:Oracle triggered exit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_YkuLQMH7t-",
        "outputId": "5280acf5-e5e7-4b7c-d277-56bb9c9a5a52"
      },
      "source": [
        "# Making model using best values for the hyper parameters\n",
        "model = tuner.get_best_models(num_models = 1)[0]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXTWmqXRJt8G",
        "outputId": "8f9bdb67-1140-4bb1-c640-ee69052d3e03"
      },
      "source": [
        "# Taking the summary of the model\n",
        "model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 26, 26, 416)       4160      \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 24, 24, 416)       1557920   \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 22, 22, 416)       1557920   \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 201344)            0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                12886080  \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 16,006,730\n",
            "Trainable params: 16,006,730\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9L38x446J2aG"
      },
      "source": [
        "## Training the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNifMUc8J0bm",
        "outputId": "8766a89c-187d-4c85-e883-f663fb4d0f3f"
      },
      "source": [
        "model.fit(train_image, train_label, epochs= 10, validation_split= 0.1, initial_epoch = 3)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 4/10\n",
            "1688/1688 [==============================] - 153s 90ms/step - loss: 0.2211 - accuracy: 0.9202 - val_loss: 0.2613 - val_accuracy: 0.9087\n",
            "Epoch 5/10\n",
            "1688/1688 [==============================] - 152s 90ms/step - loss: 0.1591 - accuracy: 0.9400 - val_loss: 0.2567 - val_accuracy: 0.9140\n",
            "Epoch 6/10\n",
            "1688/1688 [==============================] - 152s 90ms/step - loss: 0.1126 - accuracy: 0.9577 - val_loss: 0.2645 - val_accuracy: 0.9100\n",
            "Epoch 7/10\n",
            "1688/1688 [==============================] - 152s 90ms/step - loss: 0.0746 - accuracy: 0.9736 - val_loss: 0.3094 - val_accuracy: 0.9172\n",
            "Epoch 8/10\n",
            "1688/1688 [==============================] - 152s 90ms/step - loss: 0.0484 - accuracy: 0.9824 - val_loss: 0.3708 - val_accuracy: 0.9167\n",
            "Epoch 9/10\n",
            "1688/1688 [==============================] - 152s 90ms/step - loss: 0.0379 - accuracy: 0.9864 - val_loss: 0.4121 - val_accuracy: 0.9155\n",
            "Epoch 10/10\n",
            "1688/1688 [==============================] - 152s 90ms/step - loss: 0.0327 - accuracy: 0.9882 - val_loss: 0.4492 - val_accuracy: 0.9117\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f13fc5474d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KBXPG4uO-JA"
      },
      "source": [
        "  "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}